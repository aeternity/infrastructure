- name: Collect cloud instance metadata
  hosts: all
  remote_user: master
  become: yes
  gather_facts: yes
  tags: [datadog]
  vars:
    enable_aws_checks: true
  tasks:
    - name: Check if running on AWS instance
      uri:
        url: http://169.254.169.254/latest/meta-data
        timeout: 2
      register: aws_uri_check
      failed_when: False
      when:
        - enable_aws_checks|bool
        - packer_build_name is not defined

    - name: Set AWS check fact
      set_fact:
        is_aws: "{{ packer_build_name is not defined and aws_uri_check.status == 200 }}"
      when:
        - enable_aws_checks|bool

    - name: Get instance metadata facts
      ec2_metadata_facts:
      when:
        - enable_aws_checks|bool
        - is_aws

- name: Configure health check services (goss)
  hosts: all
  remote_user: master
  become: yes
  vars:
    project_user: aeternity
    goss_version: "0.3.6"

  tasks:
    - name: Create Goss source directory
      file:
        path: /usr/src/goss-{{ goss_version }}/
        state: directory
      tags:
        - goss-install

    - name: Download and unarchive Goss binary
      get_url:
        url: "https://github.com/aelsabbahy/goss/releases/download/v{{ goss_version }}/goss-linux-amd64"
        dest: /usr/src/goss-{{ goss_version }}/goss
      tags:
        - goss-install

    - name: Install Goss binary
      copy:
        src: /usr/src/goss-{{ goss_version }}/goss
        dest: /usr/bin/goss
        mode: 0755
        remote_src: true
      tags:
        - goss-install

    - name: Create Goss config directory
      file:
        path: /etc/goss/
        state: directory
      notify: restart goss
      tags:
        - goss-install

    - name: Check is systemd enabled
      stat:
        path: /run/systemd/system
      register: systemd_run_dir
      tags:
        - goss-install

    - name: Copy systemd goss config
      copy:
        src: files/goss/goss.service
        dest: "/etc/systemd/system"
        mode: 0640
      notify: reload systemd
      when: systemd_run_dir.stat.exists and systemd_run_dir.stat.isdir
      tags:
        - goss-install

    - name: Enable goss systemd service start on boot
      systemd:
        name: goss
        enabled: yes
      notify: reload systemd
      when: systemd_run_dir.stat.exists and systemd_run_dir.stat.isdir
      tags:
        - goss-install

    - name: Copy init.d goss config
      copy:
        src: files/goss/goss.conf
        dest: "/etc/init.d/goss"
        mode: 0750
      notify: restart goss
      when: not systemd_run_dir.stat.exists
      tags:
        - goss-install

    - name: Set goss.log correct permissions for goss
      file:
        path: /var/log/goss.log
        state: touch
        mode: 0640
        owner: "{{ project_user }}"
        modification_time: "preserve"
        access_time: "preserve"
      notify: restart goss
      tags:
        - goss-install

    - name: Copy test files
      copy:
        directory_mode: true
        src: ../test/goss/local/
        dest: "/etc/goss/"
      notify: restart goss
      tags:
        - goss-install

    - name: Copy health check script
      copy:
        src: ../scripts/health_check.sh
        dest: "/etc/goss/"
        mode: 0755
      notify: restart goss
      tags:
        - goss-install

  handlers:
    - name: Reload systemd
      systemd:
        daemon_reload: yes
      listen:
        - reload systemd
      notify: restart goss
      tags:
        - goss-install

    - name: Restart goss
      service:
        name: goss
        state: restarted
      listen:
        - restart goss
      tags:
        - goss-install

- name: Configure monitoring services (DataDog)
  hosts: all
  remote_user: master
  become: yes
  gather_facts: no
  tags: [datadog]

  vars:
    project_user: aeternity
    public_ipv4: "{{ ansible_ec2_public_ipv4|default(ansible_ssh_host)|default(ansible_host)|default(inventory_hostname) }}"
    datadog_api_key: "{{ lookup('hashi_vault', 'secret=secret/datadog/agent:api_key') }}"
    network_id: "{{ (node_config['fork_management']|default(dict(network_id = 'unknown')))['network_id'] }}"
    datadog_default_tags:
      - "lsb:{{ ansible_lsb.description }}"
      - "public_ipv4:{{ public_ipv4|default('unknown') }}"
      - "network_id:{{ network_id }}"
    datadog_agent_major_version: 6
    datadog_config:
      log_level: warning
      log_to_console: false
      apm_enabled: false
      use_dogstatsd: true
      process_config:
        enabled: "true" # has to be set as a string
      apm_config:
        enabled: false
      logs_enabled: true
      tags: "{{ (datadog_tags + datadog_default_tags) if datadog_tags is defined else datadog_default_tags }}"
    datadog_checks:
      system_core:
        init_config:
        instances:
          # The Agent just needs one item in instances in order to enable the check.
          # The content of the item doesnâ€™t matter.
          - foo: bar
      process:
        init_config:
        instances:
          - name: ssh
            search_string: ['sshd']
          - name: aeternity
            search_string: ['beam.smp']
          - name: epmd
            search_string: ['epmd']
            thresholds:
              warning: [1, 1]
      http_check:
        init_config:
        instances:
          - name: API
            url: "http://localhost:8080/healthz"
            # Default is false, i.e. emit events instead of service checks.
            # Recommend to set to true.
            skip_event: true
      logs_agent:
        init_config:
        instances:
        logs:
          - type: tcp
            port: 10518
            service: aeternity
            source: syslog
          - type: file
            path: "/home/{{ project_user }}/node/log/aeternity.log"
            service: aeternity
            source: lager
            sourcecategory: aeternity
          - type: file
            path: "/home/{{ project_user }}/node/log/aeternity_mining.log"
            service: aeternity
            source: lager
            sourcecategory: mining
          - type: file
            path: "/home/{{ project_user }}/node/log/aeternity_pow_cuckoo.log"
            service: aeternity
            source: lager
            sourcecategory: pow
          - type: file
            path: "/home/{{ project_user }}/node/log/aeternity_sync.log"
            service: aeternity
            source: lager
            sourcecategory: sync

  pre_tasks:
    - name: "Add dd-agent to {{ project_user }} group"
      user:
        name: dd-agent
        groups: "{{ project_user }}"
        append: yes

  roles:
    - { role: Datadog.datadog }

  post_tasks:
    - name: Install rsyslog
      apt:
        state: present
        update_cache: yes
        pkg:
        - rsyslog
    - name: Copy datadog.conf to rsyslog
      copy:
        src: files/rsyslog/datadog.conf
        dest: /etc/rsyslog.d/datadog.conf
        mode: 0600
      notify: restart rsyslogd
    - name: Copy fail2ban.conf to rsyslog
      copy:
        src: files/rsyslog/fail2ban.conf
        dest: /etc/rsyslog.d/49-fail2ban.conf
        mode: 0600
      notify: restart rsyslogd
    - name: Copy fail2ban.conf to logrotate
      copy:
        src: files/logrotate/fail2ban
        dest: /etc/logrotate.d/fail2ban
        mode: 0600
    - name: Set fail2ban.log correct permissions for syslog
      file:
        path: /var/log/fail2ban.log
        state: touch
        mode: 0640
        owner: syslog
        group: adm
        modification_time: "preserve"
        access_time: "preserve"
      notify:
        - restart rsyslogd
        - restart fail2ban
    - name: Remove default fail2ban conf.d from Debian/Ubuntu
      file:
        path: /etc/fail2ban/jail.d/defaults-debian.conf
        state: absent
      notify: restart fail2ban

  handlers:
    - name: Restart rsyslogd
      service:
        name: rsyslog
        state: restarted
        use: service_mgr|default(ansible_service_mgr)
      listen:
        - restart rsyslogd
    - name: Restart fail2ban
      service:
        name: fail2ban
        state: restarted
        use: service_mgr|default(ansible_service_mgr)
      listen:
        - restart fail2ban
